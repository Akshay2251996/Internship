{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d719dda6",
   "metadata": {},
   "source": [
    "1. Scrape the details of most viewed videos on YouTube from Wikipedia.\n",
    "Url = https://en.wikipedia.org/wiki/List_of_most-viewed_YouTube_videos\n",
    "You need to find following details:\n",
    "A) Rank\n",
    "B) Name\n",
    "C) Artist\n",
    "D) Upload date\n",
    "E) Views"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "d3f77017",
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from selenium.common.exceptions import StaleElementReferenceException, NoSuchElementException\n",
    "from selenium.webdriver.common.by import By\n",
    "import time\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f812343d",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome(r\"C:\\Users\\user\\Desktop\\internship\\webdriver\\chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "03239d46",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(\"https://en.wikipedia.org/wiki/List_of_most-viewed_YouTube_videos\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cdb47980",
   "metadata": {},
   "outputs": [],
   "source": [
    "ra,na,art,up,vie=[],[],[],[],[]\n",
    "try:\n",
    "    for i in driver.find_elements(By.XPATH,'//a[class=\"mw-redirect\"]'):\n",
    "        ra.append(i.text)     # rank\n",
    "    for i in driver.find_elements(By.XPATH,''):\n",
    "        na.append(i.text)     # name\n",
    "    for i in driver.find_elements(By.XPATH,''):\n",
    "        art.append(i.text)     # artist     \n",
    "    for i in driver.find_elements(By.XPATH,''):\n",
    "        up.append(i.text)      # for uploads\n",
    "    for i in driver.find_elements(By.XPATH,''):\n",
    "        vie.append(i.text)     # for views \n",
    "except:\n",
    "    for i in driver.find_elements(By.XPATH,'//table[@class=\"wikitable sortable jquery-tablesorter\"]'):\n",
    "        ra.append(i.text)\n",
    "        na.append(i.text)\n",
    "        art.append(i.text)\n",
    "        up.append(i.text)\n",
    "        vie.append(i.text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c3472883",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 1 1 1 1\n"
     ]
    }
   ],
   "source": [
    "print(len(ra),len(na),len(art),len(up),len(vie))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4c74a0c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>Video Name</th>\n",
       "      <th>Artist</th>\n",
       "      <th>Upload date</th>\n",
       "      <th>Views(in billions)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Top 30 most-viewed YouTube videos[3]\\nNo. Vide...</td>\n",
       "      <td>Top 30 most-viewed YouTube videos[3]\\nNo. Vide...</td>\n",
       "      <td>Top 30 most-viewed YouTube videos[3]\\nNo. Vide...</td>\n",
       "      <td>Top 30 most-viewed YouTube videos[3]\\nNo. Vide...</td>\n",
       "      <td>Top 30 most-viewed YouTube videos[3]\\nNo. Vide...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Progression of the most-viewed video on YouTub...</td>\n",
       "      <td>Progression of the most-viewed video on YouTub...</td>\n",
       "      <td>Progression of the most-viewed video on YouTub...</td>\n",
       "      <td>Progression of the most-viewed video on YouTub...</td>\n",
       "      <td>Progression of the most-viewed video on YouTub...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Rank  \\\n",
       "0  Top 30 most-viewed YouTube videos[3]\\nNo. Vide...   \n",
       "1  Progression of the most-viewed video on YouTub...   \n",
       "\n",
       "                                          Video Name  \\\n",
       "0  Top 30 most-viewed YouTube videos[3]\\nNo. Vide...   \n",
       "1  Progression of the most-viewed video on YouTub...   \n",
       "\n",
       "                                              Artist  \\\n",
       "0  Top 30 most-viewed YouTube videos[3]\\nNo. Vide...   \n",
       "1  Progression of the most-viewed video on YouTub...   \n",
       "\n",
       "                                         Upload date  \\\n",
       "0  Top 30 most-viewed YouTube videos[3]\\nNo. Vide...   \n",
       "1  Progression of the most-viewed video on YouTub...   \n",
       "\n",
       "                                  Views(in billions)  \n",
       "0  Top 30 most-viewed YouTube videos[3]\\nNo. Vide...  \n",
       "1  Progression of the most-viewed video on YouTub...  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.DataFrame({'Rank':ra,'Video Name':na,'Artist':art,'Upload date':up,'Views(in billions)':vie})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b47fa15e",
   "metadata": {},
   "source": [
    "2. Scrape the details team India‚Äôs internationalfixtures from bcci.tv. \n",
    "Url = https://www.bcci.tv/.\n",
    "You need to find following details:\n",
    "A) Match title (I.e. 1stODI)\n",
    "B) Series\n",
    "C) Place\n",
    "D) Date\n",
    "E) Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "5bcea729",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome(r\"C:\\Users\\user\\Desktop\\internship\\webdriver\\chromedriver.exe\")\n",
    "driver.get(\"https://www.bcci.tv/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "50bf6208",
   "metadata": {},
   "outputs": [],
   "source": [
    "srch=driver.find_element(By.XPATH,'//span[@class=\"menu-icon__line menu-icon__line-left\"]')\n",
    "srch.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "c6e97504",
   "metadata": {},
   "outputs": [],
   "source": [
    "int_fix=driver.find_element(By.XPATH,'//li[@class=\"nav-item\"]')\n",
    "int_fix.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "b5c8d60d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tit,ser,plc,dt,tm=[],[],[],[],[]\n",
    "for i in driver.find_elements(By.XPATH,'//span[@class=\"ng-binding\"]'):\n",
    "    tit.append(i.text)\n",
    "for i in driver.find_elements(By.XPATH,'//div[@class=\"fixture-card-mid d-flex align-items-center justify-content-between\"]'):\n",
    "    ser.append(i.text)\n",
    "for i in driver.find_elements(By.XPATH,'//div[@class=\"fix-place ng-binding ng-scope\"]'):\n",
    "    plc.append(i.text)\n",
    "for i in driver.find_elements(By.XPATH,'//div[@class=\"match-card-left match-schedule\"]'):\n",
    "    dt.append(i.text)\n",
    "for i in driver.find_elements(By.XPATH,'//div[@class=\"match-card-right match-schedule \"]'):\n",
    "    tm.append(i.text)    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "83c10b20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 8 8 8 8\n"
     ]
    }
   ],
   "source": [
    "print(len(tit),len(ser),len(plc),len(dt),len(tm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "cb1588d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Series</th>\n",
       "      <th>Place</th>\n",
       "      <th>Date Of Match</th>\n",
       "      <th>Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NEW ZEALAND TOUR OF INDIA T20 SERIES 2022-23</td>\n",
       "      <td>India\\nvs\\nNew Zealand</td>\n",
       "      <td>3rd T20I - Narendra Modi Stadium, Ahmedabad</td>\n",
       "      <td>1 FEB 2023</td>\n",
       "      <td>7:00 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>WOMENS T20I TRI-SERIES IN SOUTH AFRICA 2023</td>\n",
       "      <td>India Women\\nvs\\nSouth Africa Women</td>\n",
       "      <td>5th T20I - Buffalo Park, East London</td>\n",
       "      <td>2 FEB 2023</td>\n",
       "      <td>6:30 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AUSTRALIA TOUR OF INDIA TEST SERIES 2022-23</td>\n",
       "      <td>India\\nvs\\nAustralia</td>\n",
       "      <td>1st Test - Vidarbha Cricket Association Stadiu...</td>\n",
       "      <td>9 FEB 2023</td>\n",
       "      <td>9:30 AM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ICC WOMENS T20 WORLD CUP 2023</td>\n",
       "      <td>India Women\\nvs\\nPakistan Women</td>\n",
       "      <td>1st T20I - Newlands, Cape Town</td>\n",
       "      <td>12 FEB 2023</td>\n",
       "      <td>6:30 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ICC WOMENS T20 WORLD CUP 2023</td>\n",
       "      <td>India Women\\nvs\\nWest Indies Women</td>\n",
       "      <td>2nd T20I - Newlands, Cape Town</td>\n",
       "      <td>15 FEB 2023</td>\n",
       "      <td>6:30 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>AUSTRALIA TOUR OF INDIA TEST SERIES 2022-23</td>\n",
       "      <td>India\\nvs\\nAustralia</td>\n",
       "      <td>2nd Test - Arun Jaitley Stadium, Delhi</td>\n",
       "      <td>17 FEB 2023</td>\n",
       "      <td>9:30 AM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ICC WOMENS T20 WORLD CUP 2023</td>\n",
       "      <td>England Women\\nvs\\nIndia Women</td>\n",
       "      <td>3rd T20I - St George's Park, Gqeberha</td>\n",
       "      <td>18 FEB 2023</td>\n",
       "      <td>6:30 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ICC WOMENS T20 WORLD CUP 2023</td>\n",
       "      <td>India Women\\nvs\\nIreland Women</td>\n",
       "      <td>4th T20I - St George's Park, Gqeberha</td>\n",
       "      <td>20 FEB 2023</td>\n",
       "      <td>6:30 PM IST</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Title  \\\n",
       "0  NEW ZEALAND TOUR OF INDIA T20 SERIES 2022-23   \n",
       "1   WOMENS T20I TRI-SERIES IN SOUTH AFRICA 2023   \n",
       "2   AUSTRALIA TOUR OF INDIA TEST SERIES 2022-23   \n",
       "3                 ICC WOMENS T20 WORLD CUP 2023   \n",
       "4                 ICC WOMENS T20 WORLD CUP 2023   \n",
       "5   AUSTRALIA TOUR OF INDIA TEST SERIES 2022-23   \n",
       "6                 ICC WOMENS T20 WORLD CUP 2023   \n",
       "7                 ICC WOMENS T20 WORLD CUP 2023   \n",
       "\n",
       "                                Series  \\\n",
       "0               India\\nvs\\nNew Zealand   \n",
       "1  India Women\\nvs\\nSouth Africa Women   \n",
       "2                 India\\nvs\\nAustralia   \n",
       "3      India Women\\nvs\\nPakistan Women   \n",
       "4   India Women\\nvs\\nWest Indies Women   \n",
       "5                 India\\nvs\\nAustralia   \n",
       "6       England Women\\nvs\\nIndia Women   \n",
       "7       India Women\\nvs\\nIreland Women   \n",
       "\n",
       "                                               Place Date Of Match  \\\n",
       "0        3rd T20I - Narendra Modi Stadium, Ahmedabad    1 FEB 2023   \n",
       "1               5th T20I - Buffalo Park, East London    2 FEB 2023   \n",
       "2  1st Test - Vidarbha Cricket Association Stadiu...    9 FEB 2023   \n",
       "3                     1st T20I - Newlands, Cape Town   12 FEB 2023   \n",
       "4                     2nd T20I - Newlands, Cape Town   15 FEB 2023   \n",
       "5             2nd Test - Arun Jaitley Stadium, Delhi   17 FEB 2023   \n",
       "6              3rd T20I - St George's Park, Gqeberha   18 FEB 2023   \n",
       "7              4th T20I - St George's Park, Gqeberha   20 FEB 2023   \n",
       "\n",
       "          Time  \n",
       "0  7:00 PM IST  \n",
       "1  6:30 PM IST  \n",
       "2  9:30 AM IST  \n",
       "3  6:30 PM IST  \n",
       "4  6:30 PM IST  \n",
       "5  9:30 AM IST  \n",
       "6  6:30 PM IST  \n",
       "7  6:30 PM IST  "
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.DataFrame({'Title':tit,' Series':ser,'Place':plc,'Date Of Match':dt,'Time':tm})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "18a2ec81",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f74fab7f",
   "metadata": {},
   "source": [
    "3. Scrape the details of State-wise GDP ofIndia fromstatisticstime.com. \n",
    "Url = http://statisticstimes.com/\n",
    "You have to find following details:\n",
    "A) Rank\n",
    "B) State\n",
    "C) GSDP(18-19)- at current prices\n",
    "D) GSDP(19-20)- at current prices\n",
    "E) Share(18-19)\n",
    "F) GDP($ billion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4bce0808",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome(r\"C:\\Users\\user\\Desktop\\internship\\webdriver\\chromedriver.exe\")\n",
    "driver.get(\"http://statisticstimes.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "867821b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "srch=driver.find_element(By.XPATH,'/html/body/div[2]/div[1]/div[2]/div[2]')\n",
    "srch.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f8854176",
   "metadata": {},
   "outputs": [],
   "source": [
    "ind=driver.find_element(By.XPATH,'/html/body/div[2]/div[1]/div[2]/div[2]/div/a[3]')\n",
    "ind.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5c6d6fac",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdp=driver.find_element(By.XPATH,\"/html/body/div[2]/div[2]/div[2]/ul/li[1]/a\")\n",
    "gdp.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5e30a274",
   "metadata": {},
   "outputs": [],
   "source": [
    "ra,st,gs,dp,sh,gdp=[],[],[],[],[],[]\n",
    "try:\n",
    "    for i in driver.find_elements(By.XPATH,'//td[@class=\"data1\"]'):\n",
    "        ra.append(i.text)\n",
    "    for i in driver.find_elements(By.XPATH,'//td[@class=\"name\"]'):\n",
    "        st.append(i.text)\n",
    "    for i in driver.find_elements(By.XPATH,'//td[@class=\"data\"]'):\n",
    "        gs.append(i.text)\n",
    "    for i in driver.find_elements(By.XPATH,'//td[@class=\"data sorting_1\"]'):\n",
    "        dp.append(i.text)\n",
    "    for i in driver.find_elements(By.XPATH,'//td[@class=\"data\"]'):\n",
    "        sh.append(i.text)\n",
    "    for i in driver.find_elements(By.XPATH,'//td[@class=\"data\"]'):\n",
    "        gdp.append(i.text)\n",
    "except WebDriverException:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f4eef02c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68 68 308 66 308 308\n"
     ]
    }
   ],
   "source": [
    "print(len(ra),len(st),len(gs),len(dp),len(sh),len(gdp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a9822243",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rate</th>\n",
       "      <th>State</th>\n",
       "      <th>GSDP(18-19)</th>\n",
       "      <th>GSDP(19-20)</th>\n",
       "      <th>Shares</th>\n",
       "      <th>GDP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Maharashtra</td>\n",
       "      <td>-</td>\n",
       "      <td>2,632,792</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Tamil Nadu</td>\n",
       "      <td>13.94%</td>\n",
       "      <td>1,630,208</td>\n",
       "      <td>13.94%</td>\n",
       "      <td>13.94%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Uttar Pradesh</td>\n",
       "      <td>399.921</td>\n",
       "      <td>1,584,764</td>\n",
       "      <td>399.921</td>\n",
       "      <td>399.921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Gujarat</td>\n",
       "      <td>-</td>\n",
       "      <td>1,502,899</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Karnataka</td>\n",
       "      <td>2,039,074</td>\n",
       "      <td>1,493,127</td>\n",
       "      <td>2,039,074</td>\n",
       "      <td>2,039,074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>West Bengal</td>\n",
       "      <td>1,845,853</td>\n",
       "      <td>1,089,898</td>\n",
       "      <td>1,845,853</td>\n",
       "      <td>1,845,853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>Rajasthan</td>\n",
       "      <td>8.63%</td>\n",
       "      <td>942,586</td>\n",
       "      <td>8.63%</td>\n",
       "      <td>8.63%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>Andhra Pradesh</td>\n",
       "      <td>247.629</td>\n",
       "      <td>862,957</td>\n",
       "      <td>247.629</td>\n",
       "      <td>247.629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>Telangana</td>\n",
       "      <td>1,312,929</td>\n",
       "      <td>861,031</td>\n",
       "      <td>1,312,929</td>\n",
       "      <td>1,312,929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>Madhya Pradesh</td>\n",
       "      <td>1,215,307</td>\n",
       "      <td>809,592</td>\n",
       "      <td>1,215,307</td>\n",
       "      <td>1,215,307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>Kerala</td>\n",
       "      <td>1,687,818</td>\n",
       "      <td>781,653</td>\n",
       "      <td>1,687,818</td>\n",
       "      <td>1,687,818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>Delhi</td>\n",
       "      <td>8.39%</td>\n",
       "      <td>774,870</td>\n",
       "      <td>8.39%</td>\n",
       "      <td>8.39%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>Haryana</td>\n",
       "      <td>240.726</td>\n",
       "      <td>734,163</td>\n",
       "      <td>240.726</td>\n",
       "      <td>240.726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>Bihar</td>\n",
       "      <td>1,166,817</td>\n",
       "      <td>530,363</td>\n",
       "      <td>1,166,817</td>\n",
       "      <td>1,166,817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>Punjab</td>\n",
       "      <td>1,123,982</td>\n",
       "      <td>526,376</td>\n",
       "      <td>1,123,982</td>\n",
       "      <td>1,123,982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>Odisha</td>\n",
       "      <td>-</td>\n",
       "      <td>487,805</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>Assam</td>\n",
       "      <td>7.96%</td>\n",
       "      <td>315,881</td>\n",
       "      <td>7.96%</td>\n",
       "      <td>7.96%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>Chhattisgarh</td>\n",
       "      <td>228.290</td>\n",
       "      <td>304,063</td>\n",
       "      <td>228.290</td>\n",
       "      <td>228.290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>Jharkhand</td>\n",
       "      <td>-</td>\n",
       "      <td>297,204</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>Uttarakhand</td>\n",
       "      <td>1,186,379</td>\n",
       "      <td>245,895</td>\n",
       "      <td>1,186,379</td>\n",
       "      <td>1,186,379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21</td>\n",
       "      <td>Jammu &amp; Kashmir</td>\n",
       "      <td>1,631,977</td>\n",
       "      <td>155,956</td>\n",
       "      <td>1,631,977</td>\n",
       "      <td>1,631,977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22</td>\n",
       "      <td>Himachal Pradesh</td>\n",
       "      <td>7.91%</td>\n",
       "      <td>153,845</td>\n",
       "      <td>7.91%</td>\n",
       "      <td>7.91%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23</td>\n",
       "      <td>Goa</td>\n",
       "      <td>226.806</td>\n",
       "      <td>73,170</td>\n",
       "      <td>226.806</td>\n",
       "      <td>226.806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24</td>\n",
       "      <td>Tripura</td>\n",
       "      <td>1,156,039</td>\n",
       "      <td>49,845</td>\n",
       "      <td>1,156,039</td>\n",
       "      <td>1,156,039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>25</td>\n",
       "      <td>Chandigarh</td>\n",
       "      <td>1,091,077</td>\n",
       "      <td>42,114</td>\n",
       "      <td>1,091,077</td>\n",
       "      <td>1,091,077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>26</td>\n",
       "      <td>Puducherry</td>\n",
       "      <td>1,253,832</td>\n",
       "      <td>34,433</td>\n",
       "      <td>1,253,832</td>\n",
       "      <td>1,253,832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27</td>\n",
       "      <td>Meghalaya</td>\n",
       "      <td>5.77%</td>\n",
       "      <td>33,481</td>\n",
       "      <td>5.77%</td>\n",
       "      <td>5.77%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>28</td>\n",
       "      <td>Sikkim</td>\n",
       "      <td>165.556</td>\n",
       "      <td>28,723</td>\n",
       "      <td>165.556</td>\n",
       "      <td>165.556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>29</td>\n",
       "      <td>Manipur</td>\n",
       "      <td>793,223</td>\n",
       "      <td>27,870</td>\n",
       "      <td>793,223</td>\n",
       "      <td>793,223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>30</td>\n",
       "      <td>Nagaland</td>\n",
       "      <td>739,525</td>\n",
       "      <td>27,283</td>\n",
       "      <td>739,525</td>\n",
       "      <td>739,525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>31</td>\n",
       "      <td>Arunachal Pradesh</td>\n",
       "      <td>1,020,989</td>\n",
       "      <td>24,603</td>\n",
       "      <td>1,020,989</td>\n",
       "      <td>1,020,989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>32</td>\n",
       "      <td>Mizoram</td>\n",
       "      <td>4.99%</td>\n",
       "      <td>22,287</td>\n",
       "      <td>4.99%</td>\n",
       "      <td>4.99%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>33</td>\n",
       "      <td>Andaman &amp; Nicobar Islands</td>\n",
       "      <td>143.179</td>\n",
       "      <td>-</td>\n",
       "      <td>143.179</td>\n",
       "      <td>143.179</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rate                      State GSDP(18-19) GSDP(19-20)     Shares  \\\n",
       "0     1                Maharashtra           -   2,632,792          -   \n",
       "1     2                 Tamil Nadu      13.94%   1,630,208     13.94%   \n",
       "2     3              Uttar Pradesh     399.921   1,584,764    399.921   \n",
       "3     4                    Gujarat           -   1,502,899          -   \n",
       "4     5                  Karnataka   2,039,074   1,493,127  2,039,074   \n",
       "5     6                West Bengal   1,845,853   1,089,898  1,845,853   \n",
       "6     7                  Rajasthan       8.63%     942,586      8.63%   \n",
       "7     8             Andhra Pradesh     247.629     862,957    247.629   \n",
       "8     9                  Telangana   1,312,929     861,031  1,312,929   \n",
       "9    10             Madhya Pradesh   1,215,307     809,592  1,215,307   \n",
       "10   11                     Kerala   1,687,818     781,653  1,687,818   \n",
       "11   12                      Delhi       8.39%     774,870      8.39%   \n",
       "12   13                    Haryana     240.726     734,163    240.726   \n",
       "13   14                      Bihar   1,166,817     530,363  1,166,817   \n",
       "14   15                     Punjab   1,123,982     526,376  1,123,982   \n",
       "15   16                     Odisha           -     487,805          -   \n",
       "16   17                      Assam       7.96%     315,881      7.96%   \n",
       "17   18               Chhattisgarh     228.290     304,063    228.290   \n",
       "18   19                  Jharkhand           -     297,204          -   \n",
       "19   20                Uttarakhand   1,186,379     245,895  1,186,379   \n",
       "20   21            Jammu & Kashmir   1,631,977     155,956  1,631,977   \n",
       "21   22           Himachal Pradesh       7.91%     153,845      7.91%   \n",
       "22   23                        Goa     226.806      73,170    226.806   \n",
       "23   24                    Tripura   1,156,039      49,845  1,156,039   \n",
       "24   25                 Chandigarh   1,091,077      42,114  1,091,077   \n",
       "25   26                 Puducherry   1,253,832      34,433  1,253,832   \n",
       "26   27                  Meghalaya       5.77%      33,481      5.77%   \n",
       "27   28                     Sikkim     165.556      28,723    165.556   \n",
       "28   29                    Manipur     793,223      27,870    793,223   \n",
       "29   30                   Nagaland     739,525      27,283    739,525   \n",
       "30   31          Arunachal Pradesh   1,020,989      24,603  1,020,989   \n",
       "31   32                    Mizoram       4.99%      22,287      4.99%   \n",
       "32   33  Andaman & Nicobar Islands     143.179           -    143.179   \n",
       "\n",
       "          GDP  \n",
       "0           -  \n",
       "1      13.94%  \n",
       "2     399.921  \n",
       "3           -  \n",
       "4   2,039,074  \n",
       "5   1,845,853  \n",
       "6       8.63%  \n",
       "7     247.629  \n",
       "8   1,312,929  \n",
       "9   1,215,307  \n",
       "10  1,687,818  \n",
       "11      8.39%  \n",
       "12    240.726  \n",
       "13  1,166,817  \n",
       "14  1,123,982  \n",
       "15          -  \n",
       "16      7.96%  \n",
       "17    228.290  \n",
       "18          -  \n",
       "19  1,186,379  \n",
       "20  1,631,977  \n",
       "21      7.91%  \n",
       "22    226.806  \n",
       "23  1,156,039  \n",
       "24  1,091,077  \n",
       "25  1,253,832  \n",
       "26      5.77%  \n",
       "27    165.556  \n",
       "28    793,223  \n",
       "29    739,525  \n",
       "30  1,020,989  \n",
       "31      4.99%  \n",
       "32    143.179  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.DataFrame({'Rate':ra[0:33],'State':st[0:33],'GSDP(18-19)':gs[:33],'GSDP(19-20)':dp[0:33],'Shares':sh[0:33],'GDP':gdp[0:33]})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c70a9c4",
   "metadata": {},
   "source": [
    "4. Scrape the details of trending repositories on Github.com. \n",
    "Url = https://github.com/\n",
    "You have to find the following details:\n",
    "A) Repository title\n",
    "B) Repository description\n",
    "C) Contributors count\n",
    "D) Language used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f4359704",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome(r\"C:\\Users\\user\\Desktop\\internship\\webdriver\\chromedriver.exe\")\n",
    "driver.get(\"https://github.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "86fd39a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "op_sr=driver.find_element(By.XPATH,'/html/body/div[1]/div[1]/header/div/div[1]/div[2]/button/span/span')\n",
    "op_sr.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9cc54607",
   "metadata": {},
   "outputs": [],
   "source": [
    "source=driver.find_element(By.XPATH,'/html/body/div[1]/div[1]/header/div/div[2]/div/nav/ul/li[3]/button')\n",
    "source.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "76074f6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "trend=driver.find_element(By.XPATH,'/html/body/div[1]/div[1]/header/div/div[2]/div/nav/ul/li[3]/div/ul[3]/li[3]/a')\n",
    "trend.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a5689c2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "repo,des,lan = [],[],[]\n",
    "for i in driver.find_elements(By.XPATH,'//h1[@class=\"h3 lh-condensed\"]'):\n",
    "    repo.append(i.text)\n",
    "for i in driver.find_elements(By.XPATH,'//p[@class=\"col-9 color-fg-muted my-1 pr-4\"]'):\n",
    "    des.append(i.text)\n",
    "for i in driver.find_elements(By.XPATH,'//span[@class=\"d-inline-block ml-0 mr-3\"]'):\n",
    "    lan.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "848991d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25 23 21\n"
     ]
    }
   ],
   "source": [
    "print(len(repo),len(des),len(lan))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d6598731",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Repository title</th>\n",
       "      <th>Repository description</th>\n",
       "      <th>Language used</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>acikkaynak / deprem-yardim-frontend</td>\n",
       "      <td>afetharita.com frontend projesi. https://rc.af...</td>\n",
       "      <td>TypeScript</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>acikkaynak / deprem-yardim-backend</td>\n",
       "      <td>afetharita.com backend projesi</td>\n",
       "      <td>Python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AutumnWhj / ChatGPT-wechat-bot</td>\n",
       "      <td>ChatGPT for wechat https://github.com/AutumnWh...</td>\n",
       "      <td>TypeScript</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>fuergaosi233 / wechat-chatgpt</td>\n",
       "      <td>Use ChatGPT On Wechat via wechaty</td>\n",
       "      <td>TypeScript</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>dabit3 / gpt-travel-advisor</td>\n",
       "      <td>Create a travel itinerary for any city in the ...</td>\n",
       "      <td>TypeScript</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>f / awesome-chatgpt-prompts</td>\n",
       "      <td>This repo includes ChatGPT prompt curation to ...</td>\n",
       "      <td>HTML</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>motion-canvas / motion-canvas</td>\n",
       "      <td>Visualize Complex Ideas Programmatically</td>\n",
       "      <td>TypeScript</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>TheAlgorithms / Python</td>\n",
       "      <td>All Algorithms implemented in Python</td>\n",
       "      <td>Python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>waylaidwanderer / node-chatgpt-api</td>\n",
       "      <td>A ChatGPT implementation with support for Bing...</td>\n",
       "      <td>JavaScript</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>PowerJob / PowerJob</td>\n",
       "      <td>Enterprise job scheduling middleware with dist...</td>\n",
       "      <td>Java</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Zero6992 / chatGPT-discord-bot</td>\n",
       "      <td>Integrate ChatGPT into your own discord bot</td>\n",
       "      <td>Python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>acikkaynak / deprem-yardim-projesi</td>\n",
       "      <td>‰ΩøÁî®ChatGPTÊê≠Âª∫ÂæÆ‰ø°ËÅäÂ§©Êú∫Âô®‰∫∫ÔºåÂü∫‰∫éOpenAI APIÂíåitchatÂÆûÁé∞„ÄÇWecha...</td>\n",
       "      <td>Python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>zhayujie / chatgpt-on-wechat</td>\n",
       "      <td>Official Implementation for \"TEXTure: Semantic...</td>\n",
       "      <td>Python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>TEXTurePaper / TEXTurePaper</td>\n",
       "      <td>ChatGPT ‰∏≠ÊñáË∞ÉÊïôÊåáÂçó„ÄÇÂêÑÁßçÂú∫ÊôØ‰ΩøÁî®ÊåáÂçó„ÄÇÂ≠¶‰π†ÊÄé‰πàËÆ©ÂÆÉÂê¨‰Ω†ÁöÑËØù„ÄÇ</td>\n",
       "      <td>Go</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>PlexPt / awesome-chatgpt-prompts-zh</td>\n",
       "      <td>‰∏∫‰∏™‰∫∫ÂæÆ‰ø°Êé•ÂÖ•ChatGPT</td>\n",
       "      <td>TypeScript</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>djun / wechatbot</td>\n",
       "      <td>Tools and Techniques for Blue Team / Incident ...</td>\n",
       "      <td>Python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>A-poc / BlueTeam-Tools</td>\n",
       "      <td>Reverse engineered ChatGPT API</td>\n",
       "      <td>Python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>devfullcycle / imersao12</td>\n",
       "      <td>OpenAssistant is a chat-based assistant that u...</td>\n",
       "      <td>Rust</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>acheong08 / ChatGPT</td>\n",
       "      <td>üîÆ ChatGPT Desktop Application (Mac, Windows an...</td>\n",
       "      <td>Go</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>LAION-AI / Open-Assistant</td>\n",
       "      <td>golangÂæÆ‰ø°SDK</td>\n",
       "      <td>Python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>lencx / ChatGPT</td>\n",
       "      <td>This is an application project of 'chatgpt',on...</td>\n",
       "      <td>JavaScript</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Repository title  \\\n",
       "0   acikkaynak / deprem-yardim-frontend   \n",
       "1    acikkaynak / deprem-yardim-backend   \n",
       "2        AutumnWhj / ChatGPT-wechat-bot   \n",
       "3         fuergaosi233 / wechat-chatgpt   \n",
       "4           dabit3 / gpt-travel-advisor   \n",
       "5           f / awesome-chatgpt-prompts   \n",
       "6         motion-canvas / motion-canvas   \n",
       "7                TheAlgorithms / Python   \n",
       "8    waylaidwanderer / node-chatgpt-api   \n",
       "9                   PowerJob / PowerJob   \n",
       "10       Zero6992 / chatGPT-discord-bot   \n",
       "11   acikkaynak / deprem-yardim-projesi   \n",
       "12         zhayujie / chatgpt-on-wechat   \n",
       "13          TEXTurePaper / TEXTurePaper   \n",
       "14  PlexPt / awesome-chatgpt-prompts-zh   \n",
       "15                     djun / wechatbot   \n",
       "16               A-poc / BlueTeam-Tools   \n",
       "17             devfullcycle / imersao12   \n",
       "18                  acheong08 / ChatGPT   \n",
       "19            LAION-AI / Open-Assistant   \n",
       "20                      lencx / ChatGPT   \n",
       "\n",
       "                               Repository description Language used  \n",
       "0   afetharita.com frontend projesi. https://rc.af...    TypeScript  \n",
       "1                      afetharita.com backend projesi        Python  \n",
       "2   ChatGPT for wechat https://github.com/AutumnWh...    TypeScript  \n",
       "3                   Use ChatGPT On Wechat via wechaty    TypeScript  \n",
       "4   Create a travel itinerary for any city in the ...    TypeScript  \n",
       "5   This repo includes ChatGPT prompt curation to ...          HTML  \n",
       "6            Visualize Complex Ideas Programmatically    TypeScript  \n",
       "7                All Algorithms implemented in Python        Python  \n",
       "8   A ChatGPT implementation with support for Bing...    JavaScript  \n",
       "9   Enterprise job scheduling middleware with dist...          Java  \n",
       "10        Integrate ChatGPT into your own discord bot        Python  \n",
       "11  ‰ΩøÁî®ChatGPTÊê≠Âª∫ÂæÆ‰ø°ËÅäÂ§©Êú∫Âô®‰∫∫ÔºåÂü∫‰∫éOpenAI APIÂíåitchatÂÆûÁé∞„ÄÇWecha...        Python  \n",
       "12  Official Implementation for \"TEXTure: Semantic...        Python  \n",
       "13                ChatGPT ‰∏≠ÊñáË∞ÉÊïôÊåáÂçó„ÄÇÂêÑÁßçÂú∫ÊôØ‰ΩøÁî®ÊåáÂçó„ÄÇÂ≠¶‰π†ÊÄé‰πàËÆ©ÂÆÉÂê¨‰Ω†ÁöÑËØù„ÄÇ            Go  \n",
       "14                                     ‰∏∫‰∏™‰∫∫ÂæÆ‰ø°Êé•ÂÖ•ChatGPT    TypeScript  \n",
       "15  Tools and Techniques for Blue Team / Incident ...        Python  \n",
       "16                     Reverse engineered ChatGPT API        Python  \n",
       "17  OpenAssistant is a chat-based assistant that u...          Rust  \n",
       "18  üîÆ ChatGPT Desktop Application (Mac, Windows an...            Go  \n",
       "19                                        golangÂæÆ‰ø°SDK        Python  \n",
       "20  This is an application project of 'chatgpt',on...    JavaScript  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "git = pd.DataFrame({'Repository title':repo[0:21], 'Repository description':des[0:21], 'Language used':lan[0:21]})\n",
    "git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b2dba594",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e54444c",
   "metadata": {},
   "source": [
    "5. Scrape the details of top 100 songs on billiboard.com. \n",
    "Url = https:/www.billboard.com/\n",
    "You have to find the following details:\n",
    "A) Song name\n",
    "B) Artist name\n",
    "C) Last week rank\n",
    "D) Peak rank\n",
    "E) Weeks on board\n",
    "Note: - From the home page you have to click on the charts option then hot 100-page link through code.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "866b20e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome(r\"C:\\Users\\user\\Desktop\\internship\\webdriver\\chromedriver.exe\")\n",
    "driver.get(\"http://www.billboard.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "d281c5ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "sr=driver.find_element(By.XPATH,'/html/body/div[3]/header/div/div[4]/div/div[1]/div[1]/button')\n",
    "sr.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "6bfbac15",
   "metadata": {},
   "outputs": [],
   "source": [
    "ch=driver.find_element(By.XPATH,'/html/body/div[3]/div[9]/div/div/div/ul/li[1]/h3/button/span')\n",
    "ch.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "fab8025c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tp=driver.find_element(By.XPATH,'/html/body/div[3]/div[9]/div/div/div/ul/li[1]/ul/li[2]/a')\n",
    "tp.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "0ccdab36",
   "metadata": {},
   "outputs": [],
   "source": [
    "name,artist,lwr,pr,wob = [],[],[],[],[]\n",
    "for i in driver.find_elements(By.XPATH,'//h3[@class=\"c-title  a-no-trucate a-font-primary-bold-s u-letter-spacing-0021 lrv-u-font-size-18@tablet lrv-u-font-size-16 u-line-height-125 u-line-height-normal@mobile-max a-truncate-ellipsis u-max-width-330 u-max-width-230@tablet-only\"]'):\n",
    "    name.append(i.text)\n",
    "for i in driver.find_elements(By.XPATH,'//span[@class=\"c-label  a-no-trucate a-font-primary-s lrv-u-font-size-14@mobile-max u-line-height-normal@mobile-max u-letter-spacing-0021 lrv-u-display-block a-truncate-ellipsis-2line u-max-width-330 u-max-width-230@tablet-only\"]'):\n",
    "    artist.append(i.text)\n",
    "for i in driver.find_elements(By.XPATH,'//li[@class=\"o-chart-results-list__item // a-chart-color u-width-72 u-width-55@mobile-max u-width-55@tablet-only lrv-u-flex lrv-u-flex-shrink-0 lrv-u-align-items-center lrv-u-justify-content-center lrv-u-border-b-1 u-border-b-0@mobile-max lrv-u-border-color-grey-light u-background-color-white-064@mobile-max u-hidden@mobile-max\"]'):\n",
    "    lwr.append(i.text)\n",
    "for i in driver.find_elements(By.XPATH,'//li[@class=\"o-chart-results-list__item // a-chart-bg-color a-chart-color u-width-72 u-width-55@mobile-max u-width-55@tablet-only lrv-u-flex lrv-u-flex-shrink-0 lrv-u-align-items-center lrv-u-justify-content-center lrv-u-background-color-grey-lightest lrv-u-border-b-1 u-border-b-0@mobile-max lrv-u-border-color-grey-light u-hidden@mobile-max\"]'):\n",
    "    pr.append(i.text)\n",
    "for i in driver.find_elements(By.XPATH,'li[@class=\"o-chart-results-list__item // a-chart-color u-width-72 u-width-55@mobile-max u-width-55@tablet-only lrv-u-flex lrv-u-flex-shrink-0 lrv-u-align-items-center lrv-u-justify-content-center lrv-u-border-b-1 u-border-b-0@mobile-max lrv-u-border-color-grey-light u-background-color-white-064@mobile-max u-hidden@mobile-max\"]'):\n",
    "    wob.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "8917753a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(99, 99, 200, 200)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(name),len(artist),len(lwr),len(pr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "6cca95f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Artist</th>\n",
       "      <th>Last Week Rank</th>\n",
       "      <th>Peek Pos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Kill Bill</td>\n",
       "      <td>SZA</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Creepin'</td>\n",
       "      <td>Metro Boomin, The Weeknd &amp; 21 Savage</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Anti-Hero</td>\n",
       "      <td>Taylor Swift</td>\n",
       "      <td>2</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Unholy</td>\n",
       "      <td>Sam Smith &amp; Kim Petras</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Die For You</td>\n",
       "      <td>The Weeknd</td>\n",
       "      <td>4</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>Hey Mor</td>\n",
       "      <td>Ozuna Featuring Feid</td>\n",
       "      <td>42</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Gato de Noche</td>\n",
       "      <td>Nengo Flow &amp; Bad Bunny</td>\n",
       "      <td>32</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Heart To Heart</td>\n",
       "      <td>Mac DeMarco</td>\n",
       "      <td>45</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Never Gonna Not Dance Again</td>\n",
       "      <td>P!nk</td>\n",
       "      <td>30</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Dancin' In The Country</td>\n",
       "      <td>Tyler Hubbard</td>\n",
       "      <td>48</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>99 rows √ó 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Name                                Artist  \\\n",
       "0                     Kill Bill                                   SZA   \n",
       "1                      Creepin'  Metro Boomin, The Weeknd & 21 Savage   \n",
       "2                     Anti-Hero                          Taylor Swift   \n",
       "3                        Unholy                Sam Smith & Kim Petras   \n",
       "4                   Die For You                            The Weeknd   \n",
       "..                          ...                                   ...   \n",
       "94                      Hey Mor                  Ozuna Featuring Feid   \n",
       "95                Gato de Noche                Nengo Flow & Bad Bunny   \n",
       "96               Heart To Heart                           Mac DeMarco   \n",
       "97  Never Gonna Not Dance Again                                  P!nk   \n",
       "98       Dancin' In The Country                         Tyler Hubbard   \n",
       "\n",
       "   Last Week Rank Peek Pos  \n",
       "0               1           \n",
       "1               3        1  \n",
       "2               2           \n",
       "3               8        2  \n",
       "4               4           \n",
       "..            ...      ...  \n",
       "94             42           \n",
       "95             32        4  \n",
       "96             45           \n",
       "97             30        6  \n",
       "98             48           \n",
       "\n",
       "[99 rows x 4 columns]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bill = pd.DataFrame({'Name':name[0:99],'Artist':artist[0:99],'Last Week Rank':lwr[0:99],'Peek Pos':pr[0:99]})\n",
    "bill"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "cc5207eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d083f42c",
   "metadata": {},
   "source": [
    "6. Scrape the details of Highest sellingnovels.\n",
    "Url = https://www.theguardian.com/news/datablog/2012/aug/09/best-selling-books-all-time-fifty-shades-grey\u0002compare/\n",
    "You have to find the following details:\n",
    "A) Book name\n",
    "B) Author name\n",
    "C) Volumes sold\n",
    "D) Publisher\n",
    "E) Genre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "be4d37d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome(r\"C:\\Users\\user\\Desktop\\internship\\webdriver\\chromedriver.exe\")\n",
    "driver.get(\"https://www.theguardian.com/news/datablog/2012/aug/09/best-selling-books-all-time-fifty-shades-grey-compare\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "4033ebda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['1 Da Vinci Code,The Brown, Dan 5,094,805 Transworld Crime, Thriller & Adventure',\n",
       "  \"2 Harry Potter and the Deathly Hallows Rowling, J.K. 4,475,152 Bloomsbury Children's Fiction\",\n",
       "  \"3 Harry Potter and the Philosopher's Stone Rowling, J.K. 4,200,654 Bloomsbury Children's Fiction\",\n",
       "  \"4 Harry Potter and the Order of the Phoenix Rowling, J.K. 4,179,479 Bloomsbury Children's Fiction\",\n",
       "  '5 Fifty Shades of Grey James, E. L. 3,758,936 Random House Romance & Sagas',\n",
       "  \"6 Harry Potter and the Goblet of Fire Rowling, J.K. 3,583,215 Bloomsbury Children's Fiction\",\n",
       "  \"7 Harry Potter and the Chamber of Secrets Rowling, J.K. 3,484,047 Bloomsbury Children's Fiction\",\n",
       "  \"8 Harry Potter and the Prisoner of Azkaban Rowling, J.K. 3,377,906 Bloomsbury Children's Fiction\",\n",
       "  '9 Angels and Demons Brown, Dan 3,193,946 Transworld Crime, Thriller & Adventure',\n",
       "  \"10 Harry Potter and the Half-blood Prince:Children's Edition Rowling, J.K. 2,950,264 Bloomsbury Children's Fiction\",\n",
       "  '11 Fifty Shades Darker James, E. L. 2,479,784 Random House Romance & Sagas',\n",
       "  '12 Twilight Meyer, Stephenie 2,315,405 Little, Brown Book Young Adult Fiction',\n",
       "  '13 Girl with the Dragon Tattoo,The:Millennium Trilogy Larsson, Stieg 2,233,570 Quercus Crime, Thriller & Adventure',\n",
       "  '14 Fifty Shades Freed James, E. L. 2,193,928 Random House Romance & Sagas',\n",
       "  '15 Lost Symbol,The Brown, Dan 2,183,031 Transworld Crime, Thriller & Adventure',\n",
       "  '16 New Moon Meyer, Stephenie 2,152,737 Little, Brown Book Young Adult Fiction',\n",
       "  '17 Deception Point Brown, Dan 2,062,145 Transworld Crime, Thriller & Adventure',\n",
       "  '18 Eclipse Meyer, Stephenie 2,052,876 Little, Brown Book Young Adult Fiction',\n",
       "  '19 Lovely Bones,The Sebold, Alice 2,005,598 Pan Macmillan General & Literary Fiction',\n",
       "  '20 Curious Incident of the Dog in the Night-time,The Haddon, Mark 1,979,552 Random House General & Literary Fiction',\n",
       "  '21 Digital Fortress Brown, Dan 1,928,900 Transworld Crime, Thriller & Adventure',\n",
       "  '22 Short History of Nearly Everything,A Bryson, Bill 1,852,919 Transworld Popular Science',\n",
       "  '23 Girl Who Played with Fire,The:Millennium Trilogy Larsson, Stieg 1,814,784 Quercus Crime, Thriller & Adventure',\n",
       "  '24 Breaking Dawn Meyer, Stephenie 1,787,118 Little, Brown Book Young Adult Fiction',\n",
       "  '25 Very Hungry Caterpillar,The:The Very Hungry Caterpillar Carle, Eric 1,783,535 Penguin Picture Books',\n",
       "  '26 Gruffalo,The Donaldson, Julia 1,781,269 Pan Macmillan Picture Books',\n",
       "  \"27 Jamie's 30-Minute Meals Oliver, Jamie 1,743,266 Penguin Food & Drink: General\",\n",
       "  '28 Kite Runner,The Hosseini, Khaled 1,629,119 Bloomsbury General & Literary Fiction',\n",
       "  '29 One Day Nicholls, David 1,616,068 Hodder & Stoughton General & Literary Fiction',\n",
       "  '30 Thousand Splendid Suns,A Hosseini, Khaled 1,583,992 Bloomsbury General & Literary Fiction',\n",
       "  \"31 Girl Who Kicked the Hornets' Nest,The:Millennium Trilogy Larsson, Stieg 1,555,135 Quercus Crime, Thriller & Adventure\",\n",
       "  \"32 Time Traveler's Wife,The Niffenegger, Audrey 1,546,886 Random House General & Literary Fiction\",\n",
       "  '33 Atonement McEwan, Ian 1,539,428 Random House General & Literary Fiction',\n",
       "  \"34 Bridget Jones's Diary:A Novel Fielding, Helen 1,508,205 Pan Macmillan General & Literary Fiction\",\n",
       "  '35 World According to Clarkson,The Clarkson, Jeremy 1,489,403 Penguin Humour: Collections & General',\n",
       "  \"36 Captain Corelli's Mandolin Bernieres, Louis de 1,352,318 Random House General & Literary Fiction\",\n",
       "  '37 Sound of Laughter,The Kay, Peter 1,310,207 Random House Autobiography: General',\n",
       "  '38 Life of Pi Martel, Yann 1,310,176 Canongate General & Literary Fiction',\n",
       "  '39 Billy Connolly Stephenson, Pamela 1,231,957 HarperCollins Biography: The Arts',\n",
       "  '40 Child Called It,A Pelzer, Dave 1,217,712 Orion Autobiography: General',\n",
       "  \"41 Gruffalo's Child,The Donaldson, Julia 1,208,711 Pan Macmillan Picture Books\",\n",
       "  \"42 Angela's Ashes:A Memoir of a Childhood McCourt, Frank 1,204,058 HarperCollins Autobiography: General\",\n",
       "  '43 Birdsong Faulks, Sebastian 1,184,967 Random House General & Literary Fiction',\n",
       "  '44 Northern Lights:His Dark Materials S. Pullman, Philip 1,181,503 Scholastic Ltd. Young Adult Fiction',\n",
       "  '45 Labyrinth Mosse, Kate 1,181,093 Orion General & Literary Fiction',\n",
       "  '46 Harry Potter and the Half-blood Prince Rowling, J.K. 1,153,181 Bloomsbury Science Fiction & Fantasy',\n",
       "  '47 Help,The Stockett, Kathryn 1,132,336 Penguin General & Literary Fiction',\n",
       "  '48 Man and Boy Parsons, Tony 1,130,802 HarperCollins General & Literary Fiction',\n",
       "  '49 Memoirs of a Geisha Golden, Arthur 1,126,337 Random House General & Literary Fiction',\n",
       "  \"50 No.1 Ladies' Detective Agency,The:No.1 Ladies' Detective Agency S. McCall Smith, Alexander 1,115,549 Little, Brown Book Crime, Thriller & Adventure\",\n",
       "  '51 Island,The Hislop, Victoria 1,108,328 Headline General & Literary Fiction',\n",
       "  '52 PS, I Love You Ahern, Cecelia 1,107,379 HarperCollins General & Literary Fiction',\n",
       "  '53 You are What You Eat:The Plan That Will Change Your Life McKeith, Gillian 1,104,403 Penguin Fitness & Diet',\n",
       "  '54 Shadow of the Wind,The Zafon, Carlos Ruiz 1,092,349 Orion General & Literary Fiction',\n",
       "  \"55 Tales of Beedle the Bard,The Rowling, J.K. 1,090,847 Bloomsbury Children's Fiction\",\n",
       "  '56 Broker,The Grisham, John 1,087,262 Random House Crime, Thriller & Adventure',\n",
       "  \"57 Dr. Atkins' New Diet Revolution:The No-hunger, Luxurious Weight Loss P Atkins, Robert C. 1,054,196 Random House Fitness & Diet\",\n",
       "  '58 Subtle Knife,The:His Dark Materials S. Pullman, Philip 1,037,160 Scholastic Ltd. Young Adult Fiction',\n",
       "  '59 Eats, Shoots and Leaves:The Zero Tolerance Approach to Punctuation Truss, Lynne 1,023,688 Profile Books Group Usage & Writing Guides',\n",
       "  \"60 Delia's How to Cook:(Bk.1) Smith, Delia 1,015,956 Random House Food & Drink: General\",\n",
       "  '61 Chocolat Harris, Joanne 1,009,873 Transworld General & Literary Fiction',\n",
       "  '62 Boy in the Striped Pyjamas,The Boyne, John 1,004,414 Random House Childrens Books G Young Adult Fiction',\n",
       "  \"63 My Sister's Keeper Picoult, Jodi 1,003,780 Hodder & Stoughton General & Literary Fiction\",\n",
       "  '64 Amber Spyglass,The:His Dark Materials S. Pullman, Philip 1,002,314 Scholastic Ltd. Young Adult Fiction',\n",
       "  '65 To Kill a Mockingbird Lee, Harper 998,213 Random House General & Literary Fiction',\n",
       "  '66 Men are from Mars, Women are from Venus:A Practical Guide for Improvin Gray, John 992,846 HarperCollins Popular Culture & Media: General Interest',\n",
       "  '67 Dear Fatty French, Dawn 986,753 Random House Autobiography: The Arts',\n",
       "  '68 Short History of Tractors in Ukrainian,A Lewycka, Marina 986,115 Penguin General & Literary Fiction',\n",
       "  '69 Hannibal Harris, Thomas 970,509 Random House Crime, Thriller & Adventure',\n",
       "  '70 Lord of the Rings,The Tolkien, J. R. R. 967,466 HarperCollins Science Fiction & Fantasy',\n",
       "  '71 Stupid White Men:...and Other Sorry Excuses for the State of the Natio Moore, Michael 963,353 Penguin Current Affairs & Issues',\n",
       "  '72 Interpretation of Murder,The Rubenfeld, Jed 962,515 Headline Crime, Thriller & Adventure',\n",
       "  '73 Sharon Osbourne Extreme:My Autobiography Osbourne, Sharon 959,496 Little, Brown Book Autobiography: The Arts',\n",
       "  '74 Alchemist,The:A Fable About Following Your Dream Coelho, Paulo 956,114 HarperCollins General & Literary Fiction',\n",
       "  \"75 At My Mother's Knee ...:and Other Low Joints O'Grady, Paul 945,640 Transworld Autobiography: The Arts\",\n",
       "  '76 Notes from a Small Island Bryson, Bill 931,312 Transworld Travel Writing',\n",
       "  '77 Return of the Naked Chef,The Oliver, Jamie 925,425 Penguin Food & Drink: General',\n",
       "  '78 Bridget Jones: The Edge of Reason Fielding, Helen 924,695 Pan Macmillan General & Literary Fiction',\n",
       "  \"79 Jamie's Italy Oliver, Jamie 906,968 Penguin National & Regional Cuisine\",\n",
       "  '80 I Can Make You Thin McKenna, Paul 905,086 Transworld Fitness & Diet',\n",
       "  '81 Down Under Bryson, Bill 890,847 Transworld Travel Writing',\n",
       "  '82 Summons,The Grisham, John 869,671 Random House Crime, Thriller & Adventure',\n",
       "  '83 Small Island Levy, Andrea 869,659 Headline General & Literary Fiction',\n",
       "  '84 Nigella Express Lawson, Nigella 862,602 Random House Food & Drink: General',\n",
       "  '85 Brick Lane Ali, Monica 856,540 Transworld General & Literary Fiction',\n",
       "  \"86 Memory Keeper's Daughter,The Edwards, Kim 845,858 Penguin General & Literary Fiction\",\n",
       "  '87 Room on the Broom Donaldson, Julia 842,535 Pan Macmillan Picture Books',\n",
       "  '88 About a Boy Hornby, Nick 828,215 Penguin General & Literary Fiction',\n",
       "  '89 My Booky Wook Brand, Russell 820,563 Hodder & Stoughton Autobiography: The Arts',\n",
       "  '90 God Delusion,The Dawkins, Richard 816,907 Transworld Popular Science',\n",
       "  '91 \"Beano\" Annual,The 0 816,585 D.C. Thomson Children\\'s Annuals',\n",
       "  '92 White Teeth Smith, Zadie 815,586 Penguin General & Literary Fiction',\n",
       "  '93 House at Riverton,The Morton, Kate 814,370 Pan Macmillan General & Literary Fiction',\n",
       "  '94 Book Thief,The Zusak, Markus 809,641 Transworld General & Literary Fiction',\n",
       "  '95 Nights of Rain and Stars Binchy, Maeve 808,900 Orion General & Literary Fiction',\n",
       "  '96 Ghost,The Harris, Robert 807,311 Random House General & Literary Fiction',\n",
       "  '97 Happy Days with the Naked Chef Oliver, Jamie 794,201 Penguin Food & Drink: General',\n",
       "  '98 Hunger Games,The:Hunger Games Trilogy Collins, Suzanne 792,187 Scholastic Ltd. Young Adult Fiction',\n",
       "  \"99 Lost Boy,The:A Foster Child's Search for the Love of a Family Pelzer, Dave 791,507 Orion Biography: General\",\n",
       "  \"100 Jamie's Ministry of Food:Anyone Can Learn to Cook in 24 Hours Oliver, Jamie 791,095 Penguin Food & Drink: General\"]]"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "body = []\n",
    "for i in driver.find_elements(By.XPATH,'//tbody'):\n",
    "    body.append(i.text.split('\\n'))\n",
    "bod    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "aa9a3135",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Crime, Thriller & Adventure',\n",
       " \"Children's Fiction\",\n",
       " \"Children's Fiction\",\n",
       " \"Children's Fiction\",\n",
       " 'Romance & Sagas',\n",
       " \"Children's Fiction\",\n",
       " \"Children's Fiction\",\n",
       " \"Children's Fiction\",\n",
       " 'Crime, Thriller & Adventure',\n",
       " \"Children's Fiction\",\n",
       " 'Romance & Sagas',\n",
       " 'Young Adult Fiction',\n",
       " 'Crime, Thriller & Adventure',\n",
       " 'Romance & Sagas',\n",
       " 'Crime, Thriller & Adventure',\n",
       " 'Young Adult Fiction',\n",
       " 'Crime, Thriller & Adventure',\n",
       " 'Young Adult Fiction',\n",
       " 'General & Literary Fiction',\n",
       " 'General & Literary Fiction',\n",
       " 'Crime, Thriller & Adventure',\n",
       " 'Popular Science',\n",
       " 'Crime, Thriller & Adventure',\n",
       " 'Young Adult Fiction',\n",
       " 'Picture Books',\n",
       " 'Picture Books',\n",
       " 'Food & Drink: General',\n",
       " 'General & Literary Fiction',\n",
       " 'General & Literary Fiction',\n",
       " 'General & Literary Fiction',\n",
       " 'Crime, Thriller & Adventure',\n",
       " 'General & Literary Fiction',\n",
       " 'General & Literary Fiction',\n",
       " 'General & Literary Fiction',\n",
       " 'Humour: Collections & General',\n",
       " 'General & Literary Fiction',\n",
       " 'Autobiography: General',\n",
       " 'General & Literary Fiction',\n",
       " 'Biography: The Arts',\n",
       " 'Autobiography: General',\n",
       " 'Picture Books',\n",
       " 'Autobiography: General',\n",
       " 'General & Literary Fiction',\n",
       " 'Young Adult Fiction',\n",
       " 'General & Literary Fiction',\n",
       " 'Science Fiction & Fantasy',\n",
       " 'General & Literary Fiction',\n",
       " 'General & Literary Fiction',\n",
       " 'General & Literary Fiction',\n",
       " 'Crime, Thriller & Adventure',\n",
       " 'General & Literary Fiction',\n",
       " 'General & Literary Fiction',\n",
       " 'Fitness & Diet',\n",
       " 'General & Literary Fiction',\n",
       " \"Children's Fiction\",\n",
       " 'Crime, Thriller & Adventure',\n",
       " 'Fitness & Diet',\n",
       " 'Young Adult Fiction',\n",
       " 'Usage & Writing Guides',\n",
       " 'Food & Drink: General',\n",
       " 'General & Literary Fiction',\n",
       " 'Young Adult Fiction',\n",
       " 'General & Literary Fiction',\n",
       " 'Young Adult Fiction',\n",
       " 'General & Literary Fiction',\n",
       " 'Popular Culture & Media: General Interest',\n",
       " 'Autobiography: The Arts',\n",
       " 'General & Literary Fiction',\n",
       " 'Crime, Thriller & Adventure',\n",
       " 'Science Fiction & Fantasy',\n",
       " 'Current Affairs & Issues',\n",
       " 'Crime, Thriller & Adventure',\n",
       " 'Autobiography: The Arts',\n",
       " 'General & Literary Fiction',\n",
       " 'Autobiography: The Arts',\n",
       " 'Travel Writing',\n",
       " 'Food & Drink: General',\n",
       " 'General & Literary Fiction',\n",
       " 'National & Regional Cuisine',\n",
       " 'Fitness & Diet',\n",
       " 'Travel Writing',\n",
       " 'Crime, Thriller & Adventure',\n",
       " 'General & Literary Fiction',\n",
       " 'Food & Drink: General',\n",
       " 'General & Literary Fiction',\n",
       " 'General & Literary Fiction',\n",
       " 'Picture Books',\n",
       " 'General & Literary Fiction',\n",
       " 'Autobiography: The Arts',\n",
       " 'Popular Science',\n",
       " \"Children's Annuals\",\n",
       " 'General & Literary Fiction',\n",
       " 'General & Literary Fiction',\n",
       " 'General & Literary Fiction',\n",
       " 'General & Literary Fiction',\n",
       " 'General & Literary Fiction',\n",
       " 'Food & Drink: General',\n",
       " 'Young Adult Fiction',\n",
       " 'Biography: General',\n",
       " 'Food & Drink: General']"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen=[]\n",
    "for i in driver.find_elements(By.XPATH,'//td[@class=\"last left\"]'):\n",
    "    gen.append(i.text)\n",
    "gen    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae970e71",
   "metadata": {},
   "source": [
    "7. Scrape the details most watched tv series of all time from imdb.com. \n",
    "Url = https://www.imdb.com/list/ls095964455/\n",
    "You have to find the following details:\n",
    "A) Name\n",
    "B) Year span\n",
    "C) Genre\n",
    "D) Run time\n",
    "E) Ratings\n",
    "F) Votes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "63c554f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome(r\"C:\\Users\\user\\Desktop\\internship\\webdriver\\chromedriver.exe\")\n",
    "driver.get(\"https://www.imdb.com/list/ls095964455/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "72fe4f0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "name,year,gen,rt,rating,vote = [],[],[],[],[],[]\n",
    "\n",
    "for i in driver.find_elements(By.XPATH,'//h3[@class=\"lister-item-header\"]'):\n",
    "    na = i.text.split('(')[0]\n",
    "    name.append(na.split('.')[1])\n",
    "    year.append(i.text.split('(')[1].replace(')',' '))\n",
    "\n",
    "for i in driver.find_elements(By.XPATH,'//span[@class=\"genre\"]'):\n",
    "    gen.append(i.text)\n",
    "    \n",
    "for i in driver.find_elements(By.XPATH,'//span[@class=\"runtime\"]'):\n",
    "    rt.append(i.text)\n",
    "    \n",
    "for i in driver.find_elements(By.XPATH,'//div[@class=\"ipl-rating-widget\"]'):\n",
    "    rating.append(i.text.split('\\n')[0])\n",
    "\n",
    "for i in driver.find_elements(By.XPATH,'//span[@name=\"nv\"]'):\n",
    "    vote.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "cc5c827a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Year Span</th>\n",
       "      <th>Genre</th>\n",
       "      <th>Run Time</th>\n",
       "      <th>Ratings</th>\n",
       "      <th>Votes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Game of Thrones</td>\n",
       "      <td>2011‚Äì2019</td>\n",
       "      <td>Action, Adventure, Drama</td>\n",
       "      <td>57 min</td>\n",
       "      <td>9.2</td>\n",
       "      <td>2,122,508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Stranger Things</td>\n",
       "      <td>2016‚Äì2024</td>\n",
       "      <td>Drama, Fantasy, Horror</td>\n",
       "      <td>51 min</td>\n",
       "      <td>8.7</td>\n",
       "      <td>1,210,551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Walking Dead</td>\n",
       "      <td>2010‚Äì2022</td>\n",
       "      <td>Drama, Horror, Thriller</td>\n",
       "      <td>44 min</td>\n",
       "      <td>8.1</td>\n",
       "      <td>1,006,659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13 Reasons Why</td>\n",
       "      <td>2017‚Äì2020</td>\n",
       "      <td>Drama, Mystery, Thriller</td>\n",
       "      <td>60 min</td>\n",
       "      <td>7.5</td>\n",
       "      <td>297,049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The 100</td>\n",
       "      <td>2014‚Äì2020</td>\n",
       "      <td>Drama, Mystery, Sci-Fi</td>\n",
       "      <td>43 min</td>\n",
       "      <td>7.6</td>\n",
       "      <td>255,983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Reign</td>\n",
       "      <td>2013‚Äì2017</td>\n",
       "      <td>Drama</td>\n",
       "      <td>42 min</td>\n",
       "      <td>7.4</td>\n",
       "      <td>50,720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>A Series of Unfortunate Events</td>\n",
       "      <td>2017‚Äì2019</td>\n",
       "      <td>Adventure, Comedy, Drama</td>\n",
       "      <td>50 min</td>\n",
       "      <td>7.8</td>\n",
       "      <td>62,597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Criminal Minds</td>\n",
       "      <td>2005‚Äì</td>\n",
       "      <td>Crime, Drama, Mystery</td>\n",
       "      <td>42 min</td>\n",
       "      <td>8.1</td>\n",
       "      <td>202,829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Scream: The TV Series</td>\n",
       "      <td>2015‚Äì2019</td>\n",
       "      <td>Comedy, Crime, Drama</td>\n",
       "      <td>45 min</td>\n",
       "      <td>7.1</td>\n",
       "      <td>42,040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>The Haunting of Hill House</td>\n",
       "      <td>2018</td>\n",
       "      <td>Drama, Horror, Mystery</td>\n",
       "      <td>572 min</td>\n",
       "      <td>8.6</td>\n",
       "      <td>250,656</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows √ó 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                Name   Year Span                     Genre  \\\n",
       "0                   Game of Thrones   2011‚Äì2019   Action, Adventure, Drama   \n",
       "1                   Stranger Things   2016‚Äì2024     Drama, Fantasy, Horror   \n",
       "2                  The Walking Dead   2010‚Äì2022    Drama, Horror, Thriller   \n",
       "3                    13 Reasons Why   2017‚Äì2020   Drama, Mystery, Thriller   \n",
       "4                           The 100   2014‚Äì2020     Drama, Mystery, Sci-Fi   \n",
       "..                               ...         ...                       ...   \n",
       "95                            Reign   2013‚Äì2017                      Drama   \n",
       "96   A Series of Unfortunate Events   2017‚Äì2019   Adventure, Comedy, Drama   \n",
       "97                   Criminal Minds      2005‚Äì       Crime, Drama, Mystery   \n",
       "98            Scream: The TV Series   2015‚Äì2019       Comedy, Crime, Drama   \n",
       "99       The Haunting of Hill House        2018     Drama, Horror, Mystery   \n",
       "\n",
       "   Run Time Ratings      Votes  \n",
       "0    57 min     9.2  2,122,508  \n",
       "1    51 min     8.7  1,210,551  \n",
       "2    44 min     8.1  1,006,659  \n",
       "3    60 min     7.5    297,049  \n",
       "4    43 min     7.6    255,983  \n",
       "..      ...     ...        ...  \n",
       "95   42 min     7.4     50,720  \n",
       "96   50 min     7.8     62,597  \n",
       "97   42 min     8.1    202,829  \n",
       "98   45 min     7.1     42,040  \n",
       "99  572 min     8.6    250,656  \n",
       "\n",
       "[100 rows x 6 columns]"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "series = pd.DataFrame({'Name':name, 'Year Span':year, 'Genre':gen, 'Run Time':rt, 'Ratings':rating, 'Votes':vote})\n",
    "series"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a4c7759",
   "metadata": {},
   "source": [
    "8. Details of Datasets from UCI machine learning repositories. \n",
    "Url = https://archive.ics.uci.edu/\n",
    "You have to find the following details:\n",
    "A) Dataset name\n",
    "B) Data type\n",
    "C) Task\n",
    "D) Attribute type\n",
    "E) No of instances\n",
    "F) No of attribute\n",
    "G) Year\n",
    "Note: - from the home page you have to go to the ShowAllDataset page through code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "4ef68599",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome(r\"C:\\Users\\user\\Desktop\\internship\\webdriver\\chromedriver.exe\")\n",
    "driver.get(\"https://archive-beta.ics.uci.edu/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "d9441d56",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data=driver.find_element(By.XPATH,'/html/body/div/div[1]/div[1]/main/div/div[1]/div/div/div/a[1]')\n",
    "all_data.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "e730eebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "nb=[]\n",
    "for i in driver.find_elements(By.XPATH,'//div[@class=\"relative col-span-8 sm:col-span-7\"]'):\n",
    "    nb.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "50c6735e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Iris\\nA small classic dataset from Fisher, 1936. One of the earliest datasets used for evaluation of classification methodologies.\\nClassification\\nMultivariate\\n150 Instances\\n4 Attributes',\n",
       " 'Dry Bean Dataset\\nImages of 13,611 grains of 7 different registered dry beans were taken with a high-resolution camera. A total of 16 features; 12 dimensions and 4 shape forms, were obtained from the grains.\\nClassification\\nMultivariate\\n13.61K Instances',\n",
       " 'Heart Disease\\n4 databases: Cleveland, Hungary, Switzerland, and the VA Long Beach\\nClassification\\nMultivariate\\n303 Instances\\n13 Attributes',\n",
       " 'Adult\\nPredict whether income exceeds $50K/yr based on census data. Also known as \"Census Income\" dataset.\\nClassification\\nMultivariate\\n48.84K Instances\\n14 Attributes',\n",
       " \"Diabetes\\nThis diabetes dataset is from AIM '94\\nMultivariate, Time-Series\",\n",
       " \"Rice (Cammeo and Osmancik)\\nA total of 3810 rice grain's images were taken for the two species, processed and feature inferences were made. 7 morphological features were obtained for each grain of rice.\\nClassification\\nMultivariate\\n3.81K Instances\",\n",
       " 'Wine\\nUsing chemical analysis determine the origin of wines\\nClassification\\nMultivariate\\n178 Instances\\n13 Attributes',\n",
       " 'Car Evaluation\\nDerived from simple hierarchical decision model, this database may be useful for testing constructive induction and structure discovery methods.\\nClassification\\nMultivariate\\n1.73K Instances\\n6 Attributes',\n",
       " 'Breast Cancer Wisconsin (Diagnostic)\\nDiagnostic Wisconsin Breast Cancer Database.\\nClassification\\nMultivariate\\n569 Instances\\n30 Attributes',\n",
       " 'Mushroom\\nFrom Audobon Society Field Guide; mushrooms described in terms of physical characteristics; classification: poisonous or edible\\nClassification\\nMultivariate\\n8.12K Instances\\n22 Attributes']"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "a4f79b1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Iris',\n",
       " 'Dry Bean Dataset',\n",
       " 'Heart Disease',\n",
       " 'Adult',\n",
       " 'Diabetes',\n",
       " 'Rice (Cammeo and Osmancik)',\n",
       " 'Wine',\n",
       " 'Car Evaluation',\n",
       " 'Breast Cancer Wisconsin (Diagnostic)',\n",
       " 'Mushroom']"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "na=[]\n",
    "for i in driver.find_elements(By.XPATH,'//div[@class=\"relative col-span-8 sm:col-span-7\"]'):\n",
    "    na.append(i.text.split('\\n')[0])\n",
    "na    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "9db5cf5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' Instances',\n",
       " 'Dry Bean Dataset',\n",
       " 'Heart Disease',\n",
       " 'Adult',\n",
       " 'Diabetes',\n",
       " 'Rice (Cammeo and Osmancik)',\n",
       " 'Wine',\n",
       " 'Car Evaluation',\n",
       " 'Breast Cancer Wisconsin (Diagnostic)',\n",
       " 'Mushroom']"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt=[]\n",
    "for i in driver.find_elements(By.XPATH,'//div[@class=\"relative col-span-8 sm:col-span-7\"]'):\n",
    "    dt.append(i.text.split('\\n150')[-1].split('\\n')[0])\n",
    "dt    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b82dd83e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in driver.find_elements(By.XPATH,'//div[@class=\"relative col-span-8 sm:col-span-7\"]'):\n",
    "    na.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db85d0a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in driver.find_elements(By.XPATH,'//div[@class=\"relative col-span-8 sm:col-span-7\"]'):\n",
    "    na.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7157f5f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in driver.find_elements(By.XPATH,'//div[@class=\"relative col-span-8 sm:col-span-7\"]'):\n",
    "    na.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebf764bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in driver.find_elements(By.XPATH,'//div[@class=\"relative col-span-8 sm:col-span-7\"]'):\n",
    "    na.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "049ffc03",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in driver.find_elements(By.XPATH,'//div[@class=\"relative col-span-8 sm:col-span-7\"]'):\n",
    "    na.append(i.text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
